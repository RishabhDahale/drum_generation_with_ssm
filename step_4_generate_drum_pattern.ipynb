{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"step_4_generate_drum_pattern.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ghO60XYsVEdl"},"source":["# import library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqLKec64VOex","executionInfo":{"status":"ok","timestamp":1625030470503,"user_tz":-330,"elapsed":27038,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"df609eab-eae1-4823-eb47-981d533cf822"},"source":["!pip install librosa\n","!pip install imageio\n","!pip install soundfile\n","!pip install pretty_midi\n","!pip install mir_eval\n","!pip install dill\n","!pip install pypianoroll\n","!pip install midiutil\n","!pip install tf-slim\n","!apt-get install fluidsynth"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (20.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.0.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.19.5)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile) (1.14.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile) (2.20)\n","Requirement already satisfied: pretty_midi in /usr/local/lib/python3.7/dist-packages (0.2.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.2.10)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.19.5)\n","Requirement already satisfied: mir_eval in /usr/local/lib/python3.7/dist-packages (0.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.4)\n","Requirement already satisfied: pypianoroll in /usr/local/lib/python3.7/dist-packages (1.0.4)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.4.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.19.5)\n","Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (0.2.9)\n","Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.15.0)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.2.10)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.8.1)\n","Requirement already satisfied: midiutil in /usr/local/lib/python3.7/dist-packages (1.2.1)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf-slim) (1.15.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","fluidsynth is already the newest version (1.1.9-1).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oyaVR9jVEdo","executionInfo":{"status":"ok","timestamp":1625030473577,"user_tz":-330,"elapsed":3085,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"e4410224-e3eb-40f0-e870-7dc92d3085ad"},"source":["import warnings\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","import librosa, IPython, pickle, datetime, time, os, sys, copy, glob\n","from time import gmtime, strftime\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()\n","from tf_ops import *\n","from tf_util import *\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# show version info\n","print (\"[info] Current Time:     \" + datetime.datetime.now().strftime('%Y/%m/%d  %H:%M:%S'))\n","print (\"[info] Python Version:   \" + sys.version.split('\\n')[0].split(' ')[0])\n","print (\"[info] Working Dir:      \" + os.getcwd()+'/')\n","print (\"[info] Tensorflow:       \" + tf.__version__)\n","\n","# enable gpu usage constraint here\n","limited_gpu_usage = 1; occupied_gpu_dev = 0;\n","\n","# if gpu usage is constraint, limit certain gpu for use\n","if (limited_gpu_usage == 1):\n","    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"                       # list GPU sequence by PCI bus GPU ID                   \n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(occupied_gpu_dev)   \n","\n","    # check available GPU\n","    from tensorflow.python.client import device_lib\n","    for x in range(1, len(device_lib.list_local_devices())):\n","        print (\"[info] GPU device:       \" + device_lib.list_local_devices()[x].physical_device_desc[17:])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[info] Current Time:     2021/06/30  05:21:11\n","[info] Python Version:   3.7.10\n","[info] Working Dir:      /content/drive/My Drive/Drum_SSM/drum_generation_with_ssm/\n","[info] Tensorflow:       2.5.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tBfS-cM7VEdp"},"source":["# Reload song/bar index code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xg7n-8JIVEdq","executionInfo":{"status":"ok","timestamp":1625030473578,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"a0452391-bcab-414e-a722-c6523eca67c3"},"source":["with open('./pre_processed_data/abs_bar_idx_str_list.pkl', 'rb') as pkl_file:        \n","    abs_bar_idx_str_list = pickle.load(pkl_file)\n","    \n","print ('[info] List of [song/bar] data is loaded.')\n","print ('[info] Total bars: {}'.format(len(abs_bar_idx_str_list)))\n","print ('[info] First 5 bar code: {}'.format(abs_bar_idx_str_list[:5]))\n","print ('[info] Last  5 bar code: {}'.format(abs_bar_idx_str_list[-5:]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[info] List of [song/bar] data is loaded.\n","[info] Total bars: 2311\n","[info] First 5 bar code: ['00000_000', '00000_001', '00000_002', '00000_003', '00000_004']\n","[info] Last  5 bar code: ['00023_141', '00023_142', '00023_143', '00023_144', '00023_145']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6EbTLfOPVEdq"},"source":["# define basic CQT read function"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_4w171-VEdq","executionInfo":{"status":"ok","timestamp":1625030473579,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"72941e65-5c40-4682-9a78-4b95598fec86"},"source":["read_pooled_cqt_flist = np.sort(glob.glob('./pre_processed_data/cqt_pooled_data/*.pkl', recursive=True)).tolist()\n","print ('[info] Total # of CQT files: {}'.format(len(read_pooled_cqt_flist)))\n","\n","def get_bar_cqt_data(abd_bar_idx_str):\n","    \n","    song_idx = int(abd_bar_idx_str.split('_')[0])\n","    bar_idx = int(abd_bar_idx_str.split('_')[1])\n","    \n","    file_name = read_pooled_cqt_flist[song_idx]\n","    with open(file_name, 'rb') as pkl_file:\n","        pooled_cqt_data = pickle.load(pkl_file)  \n","        \n","    bar_cqt_data = pooled_cqt_data[bar_idx]\n","    \n","    return(bar_cqt_data)\n","    \n","print ('[info] CQT reading function defined.')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[info] Total # of CQT files: 24\n","[info] CQT reading function defined.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OvM3N0aXVEdr"},"source":["# define function to load drum data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyhHg8MaVEdr","executionInfo":{"status":"ok","timestamp":1625030473579,"user_tz":-330,"elapsed":19,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"3933c702-5113-4c97-956a-4f84a8fc84a2"},"source":["file_name = './pre_processed_data/cdsed_drum_bar_list_28_46/song_drum_bar_list_46.pkl'   \n","with open(file_name, 'rb') as pkl_file:\n","    song_drum_bar_list_46 = pickle.load(pkl_file)\n","\n","song_idx = 10; bar_idx = 30;\n","print('[info] Total # of drum tracks: {}'.format(len(song_drum_bar_list_46)))\n","print('[info] Single-bar drum data shape: {}'.format(song_drum_bar_list_46[song_idx][bar_idx].shape))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[info] Total # of drum tracks: 24\n","[info] Single-bar drum data shape: (46, 16)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aYRjv1E0VEds"},"source":["# Set note complexity parameter list [ +0 / +3 / +6 / +12 / +20]"]},{"cell_type":"code","metadata":{"id":"T0BDMoCYVEds","executionInfo":{"status":"ok","timestamp":1625030473579,"user_tz":-330,"elapsed":16,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":["bar_add_note_num_list = [0, 3, 6, 12, 20]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DTdM3OYVEds"},"source":["# define funtion to get data by index code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrWHCcFVVEdt","executionInfo":{"status":"ok","timestamp":1625030473580,"user_tz":-330,"elapsed":16,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"ec6f06f6-c324-4d64-e3e8-5716ce044513"},"source":["# read bar selection data\n","with open('./pre_processed_data/vaegan_bar_selection_index_list.pkl', 'rb') as pkl_file:\n","    bar_selection_list = pickle.load(pkl_file)\n","\n","# read song attribute\n","with open('./pre_processed_data/all_song_attribute.pkl', 'rb') as pkl_file:\n","    song_attribute_data_list = pickle.load(pkl_file)    \n","\n","\n","# define python read function\n","def read_pkl_function(index_code_in):\n","    \n","    # convert data into correct type\n","    if type(index_code_in)!=str:\n","        index_code_in = index_code_in.decode(\"utf-8\")\n","        \n","    # extract information from index code\n","    song_idx_str = index_code_in.split('_')[0]\n","    song_idx_int = int(song_idx_str)\n","    bar_idx_str = index_code_in.split('_')[1]\n","    bar_idx_int = int(bar_idx_str)\n","    \n","    # set parameter to get relative bars\n","    get_n_rtv_bars = 7\n","    rtv_bar_index = np.round(bar_selection_list[int(song_idx_str)][int(bar_idx_str), 0, 0:get_n_rtv_bars]).astype(int)\n","    rtv_bar_ratio = np.hstack([1.0, bar_selection_list[int(song_idx_str)][int(bar_idx_str), 1, 0:get_n_rtv_bars]]).astype(np.float32)\n","    \n","    # collect 8-bars CQT data\n","    cqt_data_rtv_bar_list = []\n","    \n","    for cqt_bar_idx in range(0, 8):\n","        \n","        # get current bar data\n","        if cqt_bar_idx==0:\n","            cqt_data_rtv_bar_list.append(get_bar_cqt_data(index_code_in))\n","            \n","        # get 7-relative bars data\n","        else:\n","            index_code_tmp = song_idx_str + '_' + '{:0>3}'.format(rtv_bar_index[cqt_bar_idx-1])\n","            cqt_data_rtv_bar_list.append(get_bar_cqt_data(index_code_tmp))\n","    \n","    # process CQT data\n","    cqt_data_fname_rtv_mix = np.concatenate([cqt_data_rtv_bar_list[0][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[1][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[2][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[3][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[4][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[5][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[6][:,:,np.newaxis],\n","                                             cqt_data_rtv_bar_list[7][:,:,np.newaxis]], axis=-1).astype(np.float32)\n","            \n","    # reload original MIDI drum data for reference\n","    drum_bar_data_reload = song_drum_bar_list_46[song_idx_int][bar_idx_int][:,:,np.newaxis].astype(np.float32)\n","    \n","\n","    # process song attributes    \n","    attribute_data_list = song_attribute_data_list[song_idx_int]\n","    tempo_norm_v_oh =     attribute_data_list[1].astype(np.float32)\n","    style_tag_array_oh =  attribute_data_list[2].astype(np.float32)\n","    song_progress_oh =    attribute_data_list[3][int(bar_idx_str),:].astype(np.float32)\n","    n_note_in_bar =       np.array([attribute_data_list[4][int(bar_idx_str)]]).astype(np.float32)\n","    \n","    \n","    # send back data\n","    return (cqt_data_fname_rtv_mix,  \\\n","            rtv_bar_ratio,           \\\n","            tempo_norm_v_oh,         \\\n","            style_tag_array_oh,      \\\n","            song_progress_oh,        \\\n","            n_note_in_bar,           \\\n","            drum_bar_data_reload)\n","    \n","    \n","# check data format\n","py_func_out_cqt_data,     \\\n","py_func_out_cqt_ratio,    \\\n","py_func_out_tempo_att,    \\\n","py_func_out_style_att,    \\\n","py_func_out_progress_att, \\\n","py_func_out_n_note_att,   \\\n","py_func_out_drum_arrange = read_pkl_function(abs_bar_idx_str_list[0])\n","\n","# show data format\n","print ('[info] data pkg out[0] shape: {}'.format(py_func_out_cqt_data.shape))\n","print ('[info] data pkg out[1] shape: {}'.format(py_func_out_cqt_ratio.shape))\n","print ('[info] data pkg out[2] shape: {}'.format(py_func_out_tempo_att.shape))\n","print ('[info] data pkg out[3] shape: {}'.format(py_func_out_style_att.shape))\n","print ('[info] data pkg out[4] shape: {}'.format(py_func_out_progress_att.shape))\n","print ('[info] data pkg out[5] shape: {}'.format(py_func_out_n_note_att.shape))\n","print ('[info] data pkg out[6] shape: {}'.format(py_func_out_drum_arrange.shape))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[info] data pkg out[0] shape: (84, 96, 8)\n","[info] data pkg out[1] shape: (8,)\n","[info] data pkg out[2] shape: (10,)\n","[info] data pkg out[3] shape: (16,)\n","[info] data pkg out[4] shape: (10,)\n","[info] data pkg out[5] shape: (1,)\n","[info] data pkg out[6] shape: (46, 16, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MuiISCcHVEdu"},"source":["# Define dataset.map function data shape"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBwpAXk4VEdu","executionInfo":{"status":"ok","timestamp":1625030473580,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"c9db7210-5da5-4a86-b948-0917119b2937"},"source":["trf_out0_shape = py_func_out_cqt_data.shape\n","trf_out1_shape = py_func_out_cqt_ratio.shape\n","trf_out2_shape = py_func_out_tempo_att.shape\n","trf_out3_shape = py_func_out_style_att.shape\n","trf_out4_shape = py_func_out_progress_att.shape\n","trf_out5_shape = py_func_out_n_note_att.shape\n","trf_out6_shape = py_func_out_drum_arrange.shape\n","\n","def tf_reshape_function(trf_out0, trf_out1, trf_out2, trf_out3, trf_out4, trf_out5, trf_out6):\n","    \n","    trf_out0.set_shape(trf_out0_shape)    # cqt data\n","    trf_out1.set_shape(trf_out1_shape)    # cqt data ratio\n","    trf_out2.set_shape(trf_out2_shape)    # tempo data\n","    trf_out3.set_shape(trf_out3_shape)    # style data\n","    trf_out4.set_shape(trf_out4_shape)    # song progress\n","    trf_out5.set_shape(trf_out5_shape)    # note number in bar\n","    trf_out6.set_shape(trf_out6_shape)    # drum arrange    \n","    \n","    return trf_out0, trf_out1, trf_out2, trf_out3, trf_out4, trf_out5, trf_out6\n","\n","print('[info] \\\"dataset.map\\\" function is defined.')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[info] \"dataset.map\" function is defined.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6rKrVL2VVEdv"},"source":["# Define TF dataset API for test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmLIpD1mVEdv","executionInfo":{"status":"ok","timestamp":1625030474355,"user_tz":-330,"elapsed":785,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"160f8683-b36a-4cce-f874-02b3dbb687ea"},"source":["batch_size = 64\n","\n","# extend list to match needed batch size\n","abs_bar_idx_str_list_ext = copy.deepcopy(abs_bar_idx_str_list)\n","abs_bar_idx_str_list_ext.extend(copy.deepcopy(abs_bar_idx_str_list))\n","\n","extend_list_len = ((len(abs_bar_idx_str_list)//batch_size) + \\\n","                    np.int(np.ceil((len(abs_bar_idx_str_list)%batch_size)/batch_size))) * batch_size\n","\n","abs_bar_idx_str_list_ext = abs_bar_idx_str_list_ext[:extend_list_len]\n","\n","orig_list_n = len(abs_bar_idx_str_list); extd_list_n = len(abs_bar_idx_str_list_ext); \n","print ('[info] Original list len: {}, batch num: {}'.format(orig_list_n, orig_list_n/batch_size))\n","print ('[info] Extended list len: {}, batch num: {}'.format(extd_list_n, int(extd_list_n/batch_size)))\n","\n","print ('[info] Total test index codes: {}'.format(len(abs_bar_idx_str_list_ext)))\n","\n","darr_test_dataset = tf.data.Dataset.from_tensor_slices((abs_bar_idx_str_list_ext))\n","darr_test_dataset = darr_test_dataset.map(lambda index_code_test: tuple(tf.py_func(read_pkl_function,                    \n","                                                                                   [index_code_test],\n","                                                                                   [tf.float32, \n","                                                                                    tf.float32, \n","                                                                                    tf.float32, \n","                                                                                    tf.float32, \n","                                                                                    tf.float32, \n","                                                                                    tf.float32, \n","                                                                                    tf.float32])),\n","                                           num_parallel_calls=8)\n","\n","darr_test_dataset = darr_test_dataset.map(tf_reshape_function, num_parallel_calls=8)\n","darr_test_dataset = darr_test_dataset.batch(batch_size=batch_size)\n","\n","test_iter = darr_test_dataset.make_initializable_iterator()\n","\n","# get batch data\n","batch_bar_cqt_data_test,         \\\n","batch_bar_cqt_ratio_test,        \\\n","batch_bar_tempo_data_test,       \\\n","batch_bar_style_data_test,       \\\n","batch_bar_progress_test,         \\\n","batch_bar_note_num_test,         \\\n","batch_bar_arrange_test = test_iter.get_next()\n","\n","# define TF-placeholder to hold note complexity adjust value\n","tfph_bar_add_note_num = tf.placeholder(tf.float32, shape=(1))\n","\n","print('[info] TF test Data API is defined.')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[info] Original list len: 2311, batch num: 36.109375\n","[info] Extended list len: 2368, batch num: 37\n","[info] Total test index codes: 2368\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From <ipython-input-10-586a56aaf34e>:32: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_initializable_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n","[info] TF test Data API is defined.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JwBM3bEIVEdv"},"source":["# Define Encoder Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCdrO72WVEdw","executionInfo":{"status":"ok","timestamp":1625030474356,"user_tz":-330,"elapsed":14,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"c3967581-75e8-455a-f597-42db639ac513"},"source":["# define leaky relu function\n","def lrelu(x, alpha=0.05):\n","    return tf.maximum(x, tf.multiply(x, alpha))\n","\n","n_latent = 32\n","\n","# define spectrogram encoder\n","def spec_encoder(enc_song_tempo,        # (batch_num, 10)\n","                 enc_style_id,          # (batch_num, 15)\n","                 enc_song_progress,     # (batch_num, 10)  \n","                 enc_spectrogram,       # (batch_num, 84, 96, 2)\n","                 reuse=False):\n","    \n","    with tf.variable_scope('spec_nn_enc', reuse=reuse):\n","        \n","        if reuse:\n","            tf.get_variable_scope().reuse_variables()\n","            \n","        else:\n","            assert tf.get_variable_scope().reuse is False    \n","        \n","        # define song_tempo input layer\n","        enc_song_tempo_i_layer = tf.layers.dense(inputs=enc_song_tempo,\n","                                                 units=64,\n","                                                 activation=lrelu,\n","                                                 name='enc_nn_at1')                                                    \n","\n","        # define style_id input layer\n","        enc_style_id_i_layer = tf.layers.dense(inputs=enc_style_id,\n","                                               units=64,\n","                                               activation=lrelu,\n","                                               name='enc_nn_at2')          \n","        # define song_progress input layer\n","        enc_song_progress_i_layer = tf.layers.dense(inputs=enc_song_progress,\n","                                                    units=64,\n","                                                    activation=lrelu,\n","                                                    name='enc_nn_at3')\n","        \n","        # make padding Batch / Height / Width / Channel \n","        enc_spectrogram_pad = tf.pad(enc_spectrogram, [[0, 0], [1, 1], [1, 1], [0, 0]], \"CONSTANT\")\n","                \n","        enc_conv_h1 = tf.nn.elu(instance_norm(conv2d(enc_spectrogram_pad, \n","                                                     output_dim=48,\n","                                                     ks=[4,4],\n","                                                     s=[1,1], \n","                                                     name='enc_conv1'), 'enc_bn1'))\n","    \n","        enc_conv_h2 = tf.nn.elu(instance_norm(conv2d(enc_conv_h1, \n","                                                     output_dim=48,\n","                                                     ks=[4,4],\n","                                                     s=[2,2], \n","                                                     name='enc_conv2'), 'enc_bn2'))\n","        \n","        enc_conv_h3 = tf.nn.elu(instance_norm(conv2d(enc_conv_h2,\n","                                                     output_dim=72,\n","                                                     ks=[4,4],\n","                                                     s=[2,2], \n","                                                     name='enc_conv3'), 'enc_bn3'))\n","    \n","    \n","        # flatten conv output\n","        enc_convo_flat_out = tf.reshape(enc_conv_h3, [-1, np.prod(enc_conv_h3.get_shape()[1:])])\n","        \n","        # concat all decoder input layers\n","        enc_merged_layer = tf.concat([enc_song_tempo_i_layer,       \\\n","                                      enc_style_id_i_layer,         \\\n","                                      enc_song_progress_i_layer,    \\\n","                                      enc_convo_flat_out],          \\\n","                                     axis=1,                        \\\n","                                     name='enc_nn_in_concat')\n","    \n","        \n","        enc_mlp_h1 = tf.layers.dense(inputs=enc_merged_layer,\n","                                 units=1024,\n","                                 activation=lrelu,\n","                                 name='enc_nn_mid_h1')\n","        \n","        enc_mlp_h2 = tf.layers.dense(inputs=enc_mlp_h1,\n","                                 units=1024,\n","                                 activation=lrelu,\n","                                 name='enc_nn_mid_h2')\n","\n","        enc_mlp_h2m = lrelu(enc_mlp_h2 + enc_mlp_h1*0.2)\n","        \n","        enc_mlp_h3 = tf.layers.dense(inputs=enc_mlp_h2m,\n","                                     units=1024,\n","                                     activation=lrelu,\n","                                     name='enc_nn_mid_h3')\n","        \n","        enc_mlp_h3m = lrelu(enc_mlp_h3 + enc_mlp_h2m*0.2)      \n","        \n","        \n","        # define encoder output layer\n","        z_mean = tf.layers.dense(inputs=enc_mlp_h3m,\n","                                 units=n_latent,\n","                                 activation=None,\n","                                 name='enco_mean')\n","            \n","        z_std = tf.layers.dense(inputs=enc_mlp_h3m, \n","                                units=n_latent, \n","                                activation=None,\n","                                name='enco_std')\n","        \n","        z_epsilon = tf.random_normal(tf.stack([tf.shape(enc_mlp_h3m)[0], n_latent])) \n","        \n","        z_latent  = z_mean + tf.multiply(z_epsilon, tf.exp(z_std * 0.5))\n","        \n","        enc_n_note_h1 = tf.layers.dense(inputs=enc_mlp_h3m, \n","                                        units=512, \n","                                        activation=lrelu,\n","                                        name='enc_nnp_h1')\n","\n","        enc_n_note_h2 = tf.layers.dense(inputs=enc_n_note_h1, \n","                                        units=512, \n","                                        activation=lrelu,\n","                                        name='enc_nnp_h2')        \n","        \n","        enc_n_note_pridiction = tf.layers.dense(inputs=enc_n_note_h2, \n","                                                units=1, \n","                                                activation=tf.nn.sigmoid,\n","                                                name='enco_nnp_out')\n","        \n","        enc_n_note_pridiction_x256 = (enc_n_note_pridiction * 256) - 10\n","        \n","        return z_latent, z_mean, z_std, enc_n_note_pridiction_x256\n","    \n","print ('[info] Encoder define done.')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[info] Encoder define done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_ScaYj0bVEdw"},"source":["# Defining decoder model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1GIaAHfVEdx","executionInfo":{"status":"ok","timestamp":1625030474356,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"3387936b-7d2e-46d1-f3b0-1b873b42ac7f"},"source":["dec_output_size = np.prod(trf_out6_shape)   # bar_arrange, out[5] shape: (46, 16, 1)\n","dec_output_size_4d = [-1, trf_out6_shape[0], trf_out6_shape[1], 1]\n","\n","# define leaky relu function\n","def lrelu(x, alpha=0.05):\n","    return tf.maximum(x, tf.multiply(x, alpha))\n","\n","# define spectrogram encoder\n","def spec_decoder(dec_song_tempo,        # (batch_num, 10)\n","                 dec_style_id,          # (batch_num, 15)\n","                 dec_song_progress,     # (batch_num, 10)   \n","                 dec_bar_note_num,      # (batch_num, 1)\n","                 dec_z_sampled,         # (batch_num, 32)                 \n","                 reuse=False):\n","    \n","    with tf.variable_scope('spec_nn_dec', reuse=reuse):\n","        \n","        if reuse:\n","            tf.get_variable_scope().reuse_variables()\n","            \n","        else:\n","            assert tf.get_variable_scope().reuse is False          \n","            \n","        # define song_tempo input layer\n","        dec_song_tempo_i_layer = tf.layers.dense(inputs=dec_song_tempo,\n","                                                 units=64,\n","                                                 activation=lrelu,\n","                                                 name='dec_nn_at1')                                                    \n","\n","        # define style_id input layer\n","        dec_style_id_i_layer = tf.layers.dense(inputs=dec_style_id,\n","                                               units=64,\n","                                               activation=lrelu,\n","                                               name='dec_nn_at2')          \n","        # define song_progress input layer\n","        dec_song_progress_i_layer = tf.layers.dense(inputs=dec_song_progress,\n","                                                    units=64,\n","                                                    activation=lrelu,\n","                                                    name='dec_nn_at3')\n","        \n","        # define bar_note_num input layer\n","        dec_bar_note_num_limited = tf.clip_by_value(dec_bar_note_num,\n","                                                    0.0,\n","                                                    200.0)\n","        \n","        dec_bar_note_num_i_layer = tf.layers.dense(inputs=dec_bar_note_num_limited,\n","                                                   units=64,\n","                                                   activation=lrelu,\n","                                                   name='dec_nn_at4')\n","        \n","        # define z input layer\n","        dec_z_i_layer = tf.layers.dense(inputs=dec_z_sampled,\n","                                        units=256,\n","                                        activation=lrelu,\n","                                        name='dec_nn_at5')\n","        \n","        # concat all decoder input layers\n","        dec_merged_layer = tf.concat([dec_song_tempo_i_layer,       \\\n","                                      dec_style_id_i_layer,         \\\n","                                      dec_song_progress_i_layer,    \\\n","                                      dec_bar_note_num_i_layer,     \\\n","                                      dec_z_i_layer],               \\\n","                                     axis=1,                        \\\n","                                     name='dec_nn_in_concat')\n","                \n","        dec_mlp_h1 = tf.layers.dense(inputs=dec_merged_layer,\n","                                     units=1024,\n","                                     activation=lrelu,\n","                                     name='dec_nn_mid_h1')                                     \n","        \n","        dec_mlp_h2 = tf.layers.dense(inputs=dec_mlp_h1,\n","                                     units=1024,\n","                                     activation=lrelu,\n","                                     name='dec_nn_mid_h2')   \n","        \n","        dec_mlp_h2m = lrelu(dec_mlp_h2 + dec_mlp_h1*0.2)\n","        \n","        dec_mlp_h3 = tf.layers.dense(inputs=dec_mlp_h2m,\n","                                     units=2048,\n","                                     activation=lrelu,\n","                                     name='dec_nn_mid_h3')\n","        \n","        dec_mlp_h4 = tf.layers.dense(inputs=dec_mlp_h3,\n","                                     units=2048,\n","                                     activation=lrelu,\n","                                     name='dec_nn_mid_h4')\n","        \n","        dec_mlp_h4m = lrelu(dec_mlp_h4 + dec_mlp_h3*0.2)\n","        \n","        dec_mlp_h5 = tf.layers.dense(inputs=dec_mlp_h4m,\n","                                     units=2048,\n","                                     activation=lrelu,\n","                                     name='dec_nn_mid_h5')\n","        \n","        dec_mlp_h5m = lrelu(dec_mlp_h5 + dec_mlp_h4m*0.2)\n","        \n","        dec_mlp_h6 = tf.layers.dense(inputs=dec_mlp_h5m,\n","                                     units=2048,\n","                                     activation=lrelu,\n","                                     name='dec_nn_mid_h6')\n","        \n","        dec_mlp_h6m = lrelu(dec_mlp_h6 + dec_mlp_h5m*0.2)\n","        \n","        # final output layer use tanh\n","        dec_mlp_output = tf.layers.dense(inputs=dec_mlp_h6m,\n","                                         units=dec_output_size,                        \n","                                         activation=tf.nn.tanh,\n","                                         name='dec_nn_out_final')        \n","        \n","        # normalize output range to -1.5 ~ 2.5\n","        #dec_mlp_output_norm = (dec_mlp_output * 4.0) + 0.5        \n","        dec_mlp_output_norm = lrelu((dec_mlp_output * 2.0) + 0.5)\n","        \n","        # reshape data into 4d shape\n","        dec_output_reshape = tf.reshape(dec_mlp_output_norm, dec_output_size_4d)\n","        \n","        return dec_output_reshape\n","\n","print ('[info] Decoder define done.')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[info] Decoder define done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JQoHKibhVEdz"},"source":["# Make Model Connections"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z66ZMgHBVEdz","executionInfo":{"status":"ok","timestamp":1625030475073,"user_tz":-330,"elapsed":723,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"df2e01d8-ec04-4fb6-c714-cafdcb29a20a"},"source":["# connect model for testing data\n","processed_cqt_data_test = apply_cqt_ratio(batch_bar_cqt_data_test, batch_bar_cqt_ratio_test)\n","processed_cqt_data_double_layer_test = get_matx_2_layer_tf(processed_cqt_data_test)\n","\n","vae_latent_z_test,     \\\n","vae_latent_zmn_test,   \\\n","vae_latent_zsd_test,   \\\n","vae_note_pred_test = spec_encoder(batch_bar_tempo_data_test,                   \\\n","                                  batch_bar_style_data_test,                   \\\n","                                  batch_bar_progress_test,                     \\\n","                                  processed_cqt_data_double_layer_test,        \\\n","                                  reuse=False)\n","\n","vae_drum_out_test = spec_decoder(batch_bar_tempo_data_test,                    \\\n","                                 batch_bar_style_data_test,                    \\\n","                                 batch_bar_progress_test,                      \\\n","                                 vae_note_pred_test + tfph_bar_add_note_num,   \\\n","                                 vae_latent_z_test,                            \\\n","                                 reuse=False)\n","\n","print ('[info] VAE test model is connected.')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/My Drive/Drum_SSM/drum_generation_with_ssm/tf_ops.py:16: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  warnings.warn('`tf.layers.dense` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["[info] VAE test model is connected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kOZhj0pcVEdz"},"source":["# Define all parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o0K6WXbHVEd0","executionInfo":{"status":"ok","timestamp":1625030475073,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"c953546d-a93b-4497-97d6-063221ee6602"},"source":["# Define all trainable variable\n","t_vars = tf.trainable_variables()\n","\n","# count model trainable variables\n","print('[info] Total params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars])))\n","print('[info] Encoder params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars if 'spec_nn_enc' in v.name])))\n","print('[info] Decoder params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars if 'spec_nn_dec' in v.name])))\n","\n","# collect all tf variables\n","nn_model_vars = [var for var in t_vars if 'spec_nn_enc' in var.name]\n","nn_model_vars.extend([var for var in t_vars if 'spec_nn_dec' in var.name])\n","\n","print('\\n[info] trainable variable: ')\n","print([var.name for var in nn_model_vars])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[info] Total params: 61590385\n","[info] Encoder params: 43808081\n","[info] Decoder params: 17782304\n","\n","[info] trainable variable: \n","['spec_nn_enc/enc_nn_at1/kernel:0', 'spec_nn_enc/enc_nn_at1/bias:0', 'spec_nn_enc/enc_nn_at2/kernel:0', 'spec_nn_enc/enc_nn_at2/bias:0', 'spec_nn_enc/enc_nn_at3/kernel:0', 'spec_nn_enc/enc_nn_at3/bias:0', 'spec_nn_enc/enc_conv1/Conv/weights:0', 'spec_nn_enc/enc_bn1/scale:0', 'spec_nn_enc/enc_bn1/offset:0', 'spec_nn_enc/enc_conv2/Conv/weights:0', 'spec_nn_enc/enc_bn2/scale:0', 'spec_nn_enc/enc_bn2/offset:0', 'spec_nn_enc/enc_conv3/Conv/weights:0', 'spec_nn_enc/enc_bn3/scale:0', 'spec_nn_enc/enc_bn3/offset:0', 'spec_nn_enc/enc_nn_mid_h1/kernel:0', 'spec_nn_enc/enc_nn_mid_h1/bias:0', 'spec_nn_enc/enc_nn_mid_h2/kernel:0', 'spec_nn_enc/enc_nn_mid_h2/bias:0', 'spec_nn_enc/enc_nn_mid_h3/kernel:0', 'spec_nn_enc/enc_nn_mid_h3/bias:0', 'spec_nn_enc/enco_mean/kernel:0', 'spec_nn_enc/enco_mean/bias:0', 'spec_nn_enc/enco_std/kernel:0', 'spec_nn_enc/enco_std/bias:0', 'spec_nn_enc/enc_nnp_h1/kernel:0', 'spec_nn_enc/enc_nnp_h1/bias:0', 'spec_nn_enc/enc_nnp_h2/kernel:0', 'spec_nn_enc/enc_nnp_h2/bias:0', 'spec_nn_enc/enco_nnp_out/kernel:0', 'spec_nn_enc/enco_nnp_out/bias:0', 'spec_nn_dec/dec_nn_at1/kernel:0', 'spec_nn_dec/dec_nn_at1/bias:0', 'spec_nn_dec/dec_nn_at2/kernel:0', 'spec_nn_dec/dec_nn_at2/bias:0', 'spec_nn_dec/dec_nn_at3/kernel:0', 'spec_nn_dec/dec_nn_at3/bias:0', 'spec_nn_dec/dec_nn_at4/kernel:0', 'spec_nn_dec/dec_nn_at4/bias:0', 'spec_nn_dec/dec_nn_at5/kernel:0', 'spec_nn_dec/dec_nn_at5/bias:0', 'spec_nn_dec/dec_nn_mid_h1/kernel:0', 'spec_nn_dec/dec_nn_mid_h1/bias:0', 'spec_nn_dec/dec_nn_mid_h2/kernel:0', 'spec_nn_dec/dec_nn_mid_h2/bias:0', 'spec_nn_dec/dec_nn_mid_h3/kernel:0', 'spec_nn_dec/dec_nn_mid_h3/bias:0', 'spec_nn_dec/dec_nn_mid_h4/kernel:0', 'spec_nn_dec/dec_nn_mid_h4/bias:0', 'spec_nn_dec/dec_nn_mid_h5/kernel:0', 'spec_nn_dec/dec_nn_mid_h5/bias:0', 'spec_nn_dec/dec_nn_mid_h6/kernel:0', 'spec_nn_dec/dec_nn_mid_h6/bias:0', 'spec_nn_dec/dec_nn_out_final/kernel:0', 'spec_nn_dec/dec_nn_out_final/bias:0']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nWHJ4fPyVEd0"},"source":["# Run testing loops here"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ADbfu8KxVEd0","executionInfo":{"status":"ok","timestamp":1625031195904,"user_tz":-330,"elapsed":720837,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"0bb82af0-1a30-4f6d-d2ea-c51bb5336c9e"},"source":["show_info_epoch = 1; show_info_batch = 1;\n","\n","print (\"[info] Testing cell running...\")\n","print ('[info] ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '\\n')\n","\n","# init tensorflow variables\n","init = tf.global_variables_initializer()\n","saver = tf.train.Saver(var_list=nn_model_vars)\n","darr_model_config = tf.ConfigProto(allow_soft_placement=True)\n","darr_model_config.gpu_options.allow_growth = True\n","\n","# run TF session here\n","with tf.Session(config=darr_model_config) as sess:\n","    \n","    start_time = datetime.datetime.now()\n","    \n","    sess.run(init)\n","    \n","    # reload model\n","    saver.restore(sess, './drum_generator_model/darr_model.ckpt')\n","    print ('[info] Model parameters loaded.')\n","    \n","    epoch_target = 1\n","    \n","    # run Epoch loop here\n","    for add_note_v in bar_add_note_num_list:\n","\n","        print ('\\n')\n","        print ('[info] Add note complexity: {}'.format(add_note_v))\n","        print ('[info] Test start...\\n')\n","        \n","        sess.run(test_iter.initializer)\n","\n","        note_score_test_list = []\n","\n","        session_bar_cqt_data_test_list = []\n","        session_bar_note_num_test_list = []\n","        session_bar_note_num_pred_test_list = []\n","        session_bar_arrange_test_list = []\n","        session_darr_output_test_list = []\n","        \n","        batch_target_test = np.int(len(abs_bar_idx_str_list_ext)/batch_size)        \n","        batch_runned_test = 0 \n","        \n","        # run batch loop here\n","        for batch_idx in range(0, batch_target_test):            \n","            \n","            # run model testing            \n","            session_bar_cqt_data_test,             \\\n","            session_bar_style_data_test,           \\\n","            session_bar_tempo_data_test,           \\\n","            session_bar_note_num_test,             \\\n","            session_bar_progress_test,             \\\n","            session_bar_arrange_test,              \\\n","            session_bar_note_num_pred_test,        \\\n","            session_darr_output_test = sess.run([batch_bar_cqt_data_test,  \\\n","                                       batch_bar_style_data_test,          \\\n","                                       batch_bar_tempo_data_test,          \\\n","                                       batch_bar_note_num_test,            \\\n","                                       batch_bar_progress_test,            \\\n","                                       batch_bar_arrange_test,             \\\n","                                       vae_note_pred_test,                 \\\n","                                       vae_drum_out_test],                 \\\n","                                      feed_dict={tfph_bar_add_note_num: np.array([add_note_v])})\n","            \n","            # get correct shape of data\n","            session_bar_cqt_data_test = session_bar_cqt_data_test.copy()[:,:,:,0]\n","            session_bar_arrange_test = session_bar_arrange_test.copy()[:,:,:,0]\n","            session_darr_output_test = session_darr_output_test.copy()[:,:,:,0]\n","            \n","            # calculate note score\n","            session_darr_output_test_bin = np.where(session_darr_output_test>=0.5,\n","                                                    np.ones_like(session_darr_output_test),\n","                                                    np.zeros_like(session_darr_output_test))  \n","\n","            note_score_test = 1.0 - np.sum(np.abs(                        \\\n","                session_bar_arrange_test - session_darr_output_test_bin))/np.prod(session_bar_arrange_test.shape)\n","            \n","            note_score_test_list.append(note_score_test)\n","            \n","            # record every batch data\n","            session_bar_cqt_data_test_list.append(session_bar_cqt_data_test)\n","            session_bar_note_num_test_list.append(session_bar_note_num_test)\n","            session_bar_note_num_pred_test_list.append(session_bar_note_num_pred_test)\n","            session_bar_arrange_test_list.append(session_bar_arrange_test)\n","            session_darr_output_test_list.append(session_darr_output_test)\n","                \n","            # record runned batch\n","            batch_runned_test += 1\n","            \n","            if (batch_runned_test%show_info_batch)==0:\n","                out_msg = \"[info] Batch done: [ {:3d} / {:3d} ]\".format(batch_runned_test, batch_target_test)\n","                out_msg += \",  Note score: {:.2f} %\".format(100*np.mean(note_score_test_list[-show_info_batch:]))\n","                print (out_msg)             \n","            \n","        delta_time = datetime.datetime.now() - start_time\n","        \n","        out_msg  = \"\\n[info] Test note score(Avg.): {:.2f} %\".format(100*np.mean(note_score_test_list))\n","        out_msg += \"\\n[info] test error notes per bar({} notes): {:.2f}\".format(dec_output_size, \n","                                                                                (1-np.mean(note_score_test_list))*dec_output_size)\n","        out_msg += \"\\n[info] Elapse Time: {}\".format(str(delta_time)[:-7])        \n","        print (out_msg)\n","        \n","        # save calculation result\n","        cqt_data_ary   = np.concatenate(session_bar_cqt_data_test_list, axis=0)[:len(abs_bar_idx_str_list),:]\n","        drum_original  = np.concatenate(session_bar_arrange_test_list, axis=0)[:len(abs_bar_idx_str_list),:]\n","        drum_predicted = np.concatenate(session_darr_output_test_list, axis=0)[:len(abs_bar_idx_str_list),:]\n","        dump_data_pkg = [cqt_data_ary, drum_original, drum_predicted]\n","\n","        print(\"[info] CQT data shape: {}\".format(cqt_data_ary.shape))\n","        print(\"[info] Drum data shape (Original): {}\".format(drum_original.shape))\n","        print(\"[info] Drum data shape (predicted): {}\".format(drum_predicted.shape))\n","\n","        dump_file_name = './model_out_result_add_note_{:0>2}.pkl'.format(add_note_v)\n","        with open(dump_file_name, 'wb') as pkl_file:\n","            pickle.dump(dump_data_pkg, pkl_file)\n","\n","        print ('[info] Saved file:  \\\"{}\\\"'.format(dump_file_name))\n","        \n","        # test data session end            \n","        print ('[info] Test session is finished.')   \n","    \n","# show process is end\n","print (\"\\n\\n[info] All testing process is finished.\")\n","print (\"[info] \" + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[info] Testing cell running...\n","[info] 2021-06-30 05:21:13\n","\n","INFO:tensorflow:Restoring parameters from ./drum_generator_model/darr_model.ckpt\n","[info] Model parameters loaded.\n","\n","\n","[info] Add note complexity: 0\n","[info] Test start...\n","\n","[info] Batch done: [   1 /  37 ],  Note score: 96.16 %\n","[info] Batch done: [   2 /  37 ],  Note score: 97.01 %\n","[info] Batch done: [   3 /  37 ],  Note score: 96.59 %\n","[info] Batch done: [   4 /  37 ],  Note score: 97.24 %\n","[info] Batch done: [   5 /  37 ],  Note score: 97.88 %\n","[info] Batch done: [   6 /  37 ],  Note score: 97.90 %\n","[info] Batch done: [   7 /  37 ],  Note score: 96.80 %\n","[info] Batch done: [   8 /  37 ],  Note score: 97.19 %\n","[info] Batch done: [   9 /  37 ],  Note score: 97.52 %\n","[info] Batch done: [  10 /  37 ],  Note score: 97.75 %\n","[info] Batch done: [  11 /  37 ],  Note score: 97.51 %\n","[info] Batch done: [  12 /  37 ],  Note score: 96.27 %\n","[info] Batch done: [  13 /  37 ],  Note score: 96.03 %\n","[info] Batch done: [  14 /  37 ],  Note score: 97.54 %\n","[info] Batch done: [  15 /  37 ],  Note score: 97.26 %\n","[info] Batch done: [  16 /  37 ],  Note score: 94.86 %\n","[info] Batch done: [  17 /  37 ],  Note score: 97.21 %\n","[info] Batch done: [  18 /  37 ],  Note score: 97.59 %\n","[info] Batch done: [  19 /  37 ],  Note score: 97.40 %\n","[info] Batch done: [  20 /  37 ],  Note score: 97.40 %\n","[info] Batch done: [  21 /  37 ],  Note score: 97.26 %\n","[info] Batch done: [  22 /  37 ],  Note score: 96.71 %\n","[info] Batch done: [  23 /  37 ],  Note score: 97.28 %\n","[info] Batch done: [  24 /  37 ],  Note score: 97.22 %\n","[info] Batch done: [  25 /  37 ],  Note score: 97.66 %\n","[info] Batch done: [  26 /  37 ],  Note score: 96.99 %\n","[info] Batch done: [  27 /  37 ],  Note score: 95.23 %\n","[info] Batch done: [  28 /  37 ],  Note score: 94.38 %\n","[info] Batch done: [  29 /  37 ],  Note score: 96.62 %\n","[info] Batch done: [  30 /  37 ],  Note score: 96.24 %\n","[info] Batch done: [  31 /  37 ],  Note score: 97.63 %\n","[info] Batch done: [  32 /  37 ],  Note score: 97.20 %\n","[info] Batch done: [  33 /  37 ],  Note score: 97.26 %\n","[info] Batch done: [  34 /  37 ],  Note score: 97.20 %\n","[info] Batch done: [  35 /  37 ],  Note score: 97.56 %\n","[info] Batch done: [  36 /  37 ],  Note score: 97.35 %\n","[info] Batch done: [  37 /  37 ],  Note score: 96.32 %\n","\n","[info] Test note score(Avg.): 96.95 %\n","[info] test error notes per bar(736 notes): 22.43\n","[info] Elapse Time: 0:02:32\n","[info] CQT data shape: (2311, 84, 96)\n","[info] Drum data shape (Original): (2311, 46, 16)\n","[info] Drum data shape (predicted): (2311, 46, 16)\n","[info] Saved file:  \"./model_out_result_add_note_00.pkl\"\n","[info] Test session is finished.\n","\n","\n","[info] Add note complexity: 3\n","[info] Test start...\n","\n","[info] Batch done: [   1 /  37 ],  Note score: 96.16 %\n","[info] Batch done: [   2 /  37 ],  Note score: 96.91 %\n","[info] Batch done: [   3 /  37 ],  Note score: 96.42 %\n","[info] Batch done: [   4 /  37 ],  Note score: 97.01 %\n","[info] Batch done: [   5 /  37 ],  Note score: 97.73 %\n","[info] Batch done: [   6 /  37 ],  Note score: 97.80 %\n","[info] Batch done: [   7 /  37 ],  Note score: 96.73 %\n","[info] Batch done: [   8 /  37 ],  Note score: 97.08 %\n","[info] Batch done: [   9 /  37 ],  Note score: 97.40 %\n","[info] Batch done: [  10 /  37 ],  Note score: 97.60 %\n","[info] Batch done: [  11 /  37 ],  Note score: 97.31 %\n","[info] Batch done: [  12 /  37 ],  Note score: 96.23 %\n","[info] Batch done: [  13 /  37 ],  Note score: 95.91 %\n","[info] Batch done: [  14 /  37 ],  Note score: 97.48 %\n","[info] Batch done: [  15 /  37 ],  Note score: 97.05 %\n","[info] Batch done: [  16 /  37 ],  Note score: 94.58 %\n","[info] Batch done: [  17 /  37 ],  Note score: 97.10 %\n","[info] Batch done: [  18 /  37 ],  Note score: 97.52 %\n","[info] Batch done: [  19 /  37 ],  Note score: 97.26 %\n","[info] Batch done: [  20 /  37 ],  Note score: 97.34 %\n","[info] Batch done: [  21 /  37 ],  Note score: 97.17 %\n","[info] Batch done: [  22 /  37 ],  Note score: 96.53 %\n","[info] Batch done: [  23 /  37 ],  Note score: 97.13 %\n","[info] Batch done: [  24 /  37 ],  Note score: 97.03 %\n","[info] Batch done: [  25 /  37 ],  Note score: 97.61 %\n","[info] Batch done: [  26 /  37 ],  Note score: 96.91 %\n","[info] Batch done: [  27 /  37 ],  Note score: 95.03 %\n","[info] Batch done: [  28 /  37 ],  Note score: 94.20 %\n","[info] Batch done: [  29 /  37 ],  Note score: 96.52 %\n","[info] Batch done: [  30 /  37 ],  Note score: 96.23 %\n","[info] Batch done: [  31 /  37 ],  Note score: 97.47 %\n","[info] Batch done: [  32 /  37 ],  Note score: 97.04 %\n","[info] Batch done: [  33 /  37 ],  Note score: 97.14 %\n","[info] Batch done: [  34 /  37 ],  Note score: 97.08 %\n","[info] Batch done: [  35 /  37 ],  Note score: 97.44 %\n","[info] Batch done: [  36 /  37 ],  Note score: 97.27 %\n","[info] Batch done: [  37 /  37 ],  Note score: 96.29 %\n","\n","[info] Test note score(Avg.): 96.83 %\n","[info] test error notes per bar(736 notes): 23.33\n","[info] Elapse Time: 0:04:44\n","[info] CQT data shape: (2311, 84, 96)\n","[info] Drum data shape (Original): (2311, 46, 16)\n","[info] Drum data shape (predicted): (2311, 46, 16)\n","[info] Saved file:  \"./model_out_result_add_note_03.pkl\"\n","[info] Test session is finished.\n","\n","\n","[info] Add note complexity: 6\n","[info] Test start...\n","\n","[info] Batch done: [   1 /  37 ],  Note score: 95.99 %\n","[info] Batch done: [   2 /  37 ],  Note score: 96.80 %\n","[info] Batch done: [   3 /  37 ],  Note score: 96.24 %\n","[info] Batch done: [   4 /  37 ],  Note score: 96.88 %\n","[info] Batch done: [   5 /  37 ],  Note score: 97.59 %\n","[info] Batch done: [   6 /  37 ],  Note score: 97.61 %\n","[info] Batch done: [   7 /  37 ],  Note score: 96.62 %\n","[info] Batch done: [   8 /  37 ],  Note score: 96.96 %\n","[info] Batch done: [   9 /  37 ],  Note score: 97.36 %\n","[info] Batch done: [  10 /  37 ],  Note score: 97.67 %\n","[info] Batch done: [  11 /  37 ],  Note score: 97.18 %\n","[info] Batch done: [  12 /  37 ],  Note score: 96.09 %\n","[info] Batch done: [  13 /  37 ],  Note score: 95.82 %\n","[info] Batch done: [  14 /  37 ],  Note score: 97.48 %\n","[info] Batch done: [  15 /  37 ],  Note score: 96.85 %\n","[info] Batch done: [  16 /  37 ],  Note score: 94.49 %\n","[info] Batch done: [  17 /  37 ],  Note score: 96.99 %\n","[info] Batch done: [  18 /  37 ],  Note score: 97.45 %\n","[info] Batch done: [  19 /  37 ],  Note score: 97.18 %\n","[info] Batch done: [  20 /  37 ],  Note score: 97.26 %\n","[info] Batch done: [  21 /  37 ],  Note score: 97.11 %\n","[info] Batch done: [  22 /  37 ],  Note score: 96.47 %\n","[info] Batch done: [  23 /  37 ],  Note score: 97.08 %\n","[info] Batch done: [  24 /  37 ],  Note score: 96.98 %\n","[info] Batch done: [  25 /  37 ],  Note score: 97.35 %\n","[info] Batch done: [  26 /  37 ],  Note score: 96.82 %\n","[info] Batch done: [  27 /  37 ],  Note score: 94.83 %\n","[info] Batch done: [  28 /  37 ],  Note score: 94.20 %\n","[info] Batch done: [  29 /  37 ],  Note score: 96.27 %\n","[info] Batch done: [  30 /  37 ],  Note score: 96.07 %\n","[info] Batch done: [  31 /  37 ],  Note score: 97.38 %\n","[info] Batch done: [  32 /  37 ],  Note score: 96.88 %\n","[info] Batch done: [  33 /  37 ],  Note score: 97.06 %\n","[info] Batch done: [  34 /  37 ],  Note score: 96.91 %\n","[info] Batch done: [  35 /  37 ],  Note score: 97.33 %\n","[info] Batch done: [  36 /  37 ],  Note score: 97.28 %\n","[info] Batch done: [  37 /  37 ],  Note score: 96.19 %\n","\n","[info] Test note score(Avg.): 96.72 %\n","[info] test error notes per bar(736 notes): 24.12\n","[info] Elapse Time: 0:07:06\n","[info] CQT data shape: (2311, 84, 96)\n","[info] Drum data shape (Original): (2311, 46, 16)\n","[info] Drum data shape (predicted): (2311, 46, 16)\n","[info] Saved file:  \"./model_out_result_add_note_06.pkl\"\n","[info] Test session is finished.\n","\n","\n","[info] Add note complexity: 12\n","[info] Test start...\n","\n","[info] Batch done: [   1 /  37 ],  Note score: 95.53 %\n","[info] Batch done: [   2 /  37 ],  Note score: 96.33 %\n","[info] Batch done: [   3 /  37 ],  Note score: 95.82 %\n","[info] Batch done: [   4 /  37 ],  Note score: 96.54 %\n","[info] Batch done: [   5 /  37 ],  Note score: 97.13 %\n","[info] Batch done: [   6 /  37 ],  Note score: 97.23 %\n","[info] Batch done: [   7 /  37 ],  Note score: 96.13 %\n","[info] Batch done: [   8 /  37 ],  Note score: 96.53 %\n","[info] Batch done: [   9 /  37 ],  Note score: 96.85 %\n","[info] Batch done: [  10 /  37 ],  Note score: 97.11 %\n","[info] Batch done: [  11 /  37 ],  Note score: 96.80 %\n","[info] Batch done: [  12 /  37 ],  Note score: 95.68 %\n","[info] Batch done: [  13 /  37 ],  Note score: 95.34 %\n","[info] Batch done: [  14 /  37 ],  Note score: 96.97 %\n","[info] Batch done: [  15 /  37 ],  Note score: 96.41 %\n","[info] Batch done: [  16 /  37 ],  Note score: 94.00 %\n","[info] Batch done: [  17 /  37 ],  Note score: 96.52 %\n","[info] Batch done: [  18 /  37 ],  Note score: 96.97 %\n","[info] Batch done: [  19 /  37 ],  Note score: 96.78 %\n","[info] Batch done: [  20 /  37 ],  Note score: 96.79 %\n","[info] Batch done: [  21 /  37 ],  Note score: 96.66 %\n","[info] Batch done: [  22 /  37 ],  Note score: 95.99 %\n","[info] Batch done: [  23 /  37 ],  Note score: 96.57 %\n","[info] Batch done: [  24 /  37 ],  Note score: 96.57 %\n","[info] Batch done: [  25 /  37 ],  Note score: 97.01 %\n","[info] Batch done: [  26 /  37 ],  Note score: 96.41 %\n","[info] Batch done: [  27 /  37 ],  Note score: 94.30 %\n","[info] Batch done: [  28 /  37 ],  Note score: 93.65 %\n","[info] Batch done: [  29 /  37 ],  Note score: 95.86 %\n","[info] Batch done: [  30 /  37 ],  Note score: 95.57 %\n","[info] Batch done: [  31 /  37 ],  Note score: 96.83 %\n","[info] Batch done: [  32 /  37 ],  Note score: 96.45 %\n","[info] Batch done: [  33 /  37 ],  Note score: 96.76 %\n","[info] Batch done: [  34 /  37 ],  Note score: 96.52 %\n","[info] Batch done: [  35 /  37 ],  Note score: 96.89 %\n","[info] Batch done: [  36 /  37 ],  Note score: 96.84 %\n","[info] Batch done: [  37 /  37 ],  Note score: 95.72 %\n","\n","[info] Test note score(Avg.): 96.27 %\n","[info] test error notes per bar(736 notes): 27.44\n","[info] Elapse Time: 0:09:27\n","[info] CQT data shape: (2311, 84, 96)\n","[info] Drum data shape (Original): (2311, 46, 16)\n","[info] Drum data shape (predicted): (2311, 46, 16)\n","[info] Saved file:  \"./model_out_result_add_note_12.pkl\"\n","[info] Test session is finished.\n","\n","\n","[info] Add note complexity: 20\n","[info] Test start...\n","\n","[info] Batch done: [   1 /  37 ],  Note score: 94.98 %\n","[info] Batch done: [   2 /  37 ],  Note score: 95.69 %\n","[info] Batch done: [   3 /  37 ],  Note score: 95.36 %\n","[info] Batch done: [   4 /  37 ],  Note score: 96.21 %\n","[info] Batch done: [   5 /  37 ],  Note score: 96.56 %\n","[info] Batch done: [   6 /  37 ],  Note score: 96.63 %\n","[info] Batch done: [   7 /  37 ],  Note score: 95.56 %\n","[info] Batch done: [   8 /  37 ],  Note score: 96.08 %\n","[info] Batch done: [   9 /  37 ],  Note score: 96.32 %\n","[info] Batch done: [  10 /  37 ],  Note score: 96.59 %\n","[info] Batch done: [  11 /  37 ],  Note score: 96.20 %\n","[info] Batch done: [  12 /  37 ],  Note score: 95.14 %\n","[info] Batch done: [  13 /  37 ],  Note score: 94.89 %\n","[info] Batch done: [  14 /  37 ],  Note score: 96.54 %\n","[info] Batch done: [  15 /  37 ],  Note score: 95.89 %\n","[info] Batch done: [  16 /  37 ],  Note score: 93.51 %\n","[info] Batch done: [  17 /  37 ],  Note score: 95.92 %\n","[info] Batch done: [  18 /  37 ],  Note score: 96.52 %\n","[info] Batch done: [  19 /  37 ],  Note score: 96.11 %\n","[info] Batch done: [  20 /  37 ],  Note score: 96.26 %\n","[info] Batch done: [  21 /  37 ],  Note score: 96.08 %\n","[info] Batch done: [  22 /  37 ],  Note score: 95.39 %\n","[info] Batch done: [  23 /  37 ],  Note score: 95.95 %\n","[info] Batch done: [  24 /  37 ],  Note score: 96.02 %\n","[info] Batch done: [  25 /  37 ],  Note score: 96.54 %\n","[info] Batch done: [  26 /  37 ],  Note score: 95.90 %\n","[info] Batch done: [  27 /  37 ],  Note score: 93.85 %\n","[info] Batch done: [  28 /  37 ],  Note score: 93.07 %\n","[info] Batch done: [  29 /  37 ],  Note score: 95.27 %\n","[info] Batch done: [  30 /  37 ],  Note score: 95.11 %\n","[info] Batch done: [  31 /  37 ],  Note score: 96.25 %\n","[info] Batch done: [  32 /  37 ],  Note score: 95.96 %\n","[info] Batch done: [  33 /  37 ],  Note score: 96.52 %\n","[info] Batch done: [  34 /  37 ],  Note score: 96.38 %\n","[info] Batch done: [  35 /  37 ],  Note score: 96.34 %\n","[info] Batch done: [  36 /  37 ],  Note score: 96.28 %\n","[info] Batch done: [  37 /  37 ],  Note score: 95.12 %\n","\n","[info] Test note score(Avg.): 95.76 %\n","[info] test error notes per bar(736 notes): 31.22\n","[info] Elapse Time: 0:11:55\n","[info] CQT data shape: (2311, 84, 96)\n","[info] Drum data shape (Original): (2311, 46, 16)\n","[info] Drum data shape (predicted): (2311, 46, 16)\n","[info] Saved file:  \"./model_out_result_add_note_20.pkl\"\n","[info] Test session is finished.\n","\n","\n","[info] All testing process is finished.\n","[info] 2021-06-30 05:33:14\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2PBpPe50VEd0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOWRT6F3VEd1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TClkUl0vVEd1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSE6EW1AVEd1"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2jdgK91VEd1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajq6hvCnVEd1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yjhob6b1VEd1"},"source":["# ensure DIR"]},{"cell_type":"code","metadata":{"id":"RVoFXaA2VEd1","executionInfo":{"status":"ok","timestamp":1625031195907,"user_tz":-330,"elapsed":20,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":["def ensure_dir(file_path):\n","    directory = os.path.dirname(file_path)\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tY8f75MSVEd2"},"source":["# save s100 p00n/p03n/p06n/p12n/p20n test result here"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"xUVU2tsuVEd2","executionInfo":{"status":"error","timestamp":1625031197184,"user_tz":-330,"elapsed":1293,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"69dde237-380d-4eb0-bf0e-3f46c8e05da8"},"source":["test_result_train_pp = [session_bar_cqt_data_train_list,\n","                        session_bar_note_num_train_list,\n","                        session_bar_note_num_pred_train_list,\n","                        session_bar_arrange_train_list,\n","                        session_darr_output_train_list]\n","\n","\n","test_s100_result_fname = './model_test_result_bm24_vaegan/{}/rc_loss_{}/'.format(chkpt_ver, rc_loss_ver)\n","test_s100_result_fname += 'bm24_{}_result_pkg.pkl'.format(add_note_ver)\n","\n","ensure_dir(test_s100_result_fname)\n","with open(test_s100_result_fname, 'wb') as pkl_file:\n","    pickle.dump(test_result_train_pp, pkl_file)\n","    \n","print ('[info] s100 {}, {}, {} test result saved.'.format(chkpt_ver, rc_loss_ver, add_note_ver))\n","print ('[info] saved file:  \\\"{}\\\"'.format(test_s100_result_fname))"],"execution_count":17,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-a700ac3c4323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_result_train_pp = [session_bar_cqt_data_train_list,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0msession_bar_note_num_train_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0msession_bar_note_num_pred_train_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0msession_bar_arrange_train_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         session_darr_output_train_list]\n","\u001b[0;31mNameError\u001b[0m: name 'session_bar_cqt_data_train_list' is not defined"]}]},{"cell_type":"code","metadata":{"id":"emKeWn__VEd2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"21inPfrZVEd2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mh7YLw02VEd2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eg-GCbZ8VEd2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Da3bUcmPVEd2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqY2gg2aVEd3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgBUOLU7VEd3","executionInfo":{"status":"aborted","timestamp":1625031197182,"user_tz":-330,"elapsed":1285,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":[""],"execution_count":null,"outputs":[]}]}