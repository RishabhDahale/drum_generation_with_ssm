{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"step_2_generate_drum_ssm_from_melodic_ssm.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OimchhIxpK0p"},"source":["# import library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LjgvnJHp7WB","executionInfo":{"status":"ok","timestamp":1625029494445,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"c3ce6fcc-5bb6-411d-f35a-4eb101e99def"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","# os.makedirs(\"/content/drive/MyDrive/Drum_SSM/drum_generation_with_ssm\")\n","os.chdir(\"/content/drive/MyDrive/Drum_SSM/drum_generation_with_ssm\")\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","drum_generator_model   step_1_midi_data_preprocessing.ipynb\n","generated_samples.zip  step_2_generate_drum_ssm_from_melodic_ssm.ipynb\n","input_midi\t       step_3_extract_bar_selection_info.ipynb\n","misc\t\t       step_4_generate_drum_pattern.ipynb\n","output_midi\t       step_5_convert_data_into_MIDI.ipynb\n","pre_processed_data     tf_ops.py\n","__pycache__\t       tf_util.py\n","README.md\t       track22_bj.png\n","ssm_generator_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oT8S-5C4p95c","executionInfo":{"status":"ok","timestamp":1625029515684,"user_tz":-330,"elapsed":21242,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"be9c6d1d-f9ee-4c31-da1a-4fdfbb889d52"},"source":["!pip install librosa\n","!pip install imageio\n","!pip install soundfile\n","!pip install pretty_midi\n","!pip install mir_eval\n","!pip install dill\n","!pip install pypianoroll\n","!pip install midiutil\n","!pip install tf-slim\n","!apt-get install fluidsynth"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (20.9)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.5)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.0.0)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.19.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile) (1.14.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile) (2.20)\n","Requirement already satisfied: pretty_midi in /usr/local/lib/python3.7/dist-packages (0.2.9)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.19.5)\n","Requirement already satisfied: mir_eval in /usr/local/lib/python3.7/dist-packages (0.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.4)\n","Requirement already satisfied: pypianoroll in /usr/local/lib/python3.7/dist-packages (1.0.4)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.19.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.4.1)\n","Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (0.2.9)\n","Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (3.2.2)\n","Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.8.1)\n","Requirement already satisfied: midiutil in /usr/local/lib/python3.7/dist-packages (1.2.1)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim) (0.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf-slim) (1.15.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","fluidsynth is already the newest version (1.1.9-1).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6pRBSqgpK0s","executionInfo":{"status":"ok","timestamp":1625029518548,"user_tz":-330,"elapsed":2875,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"36361662-6be4-47ff-e102-efb394aef6a1"},"source":["import warnings\n","warnings.filterwarnings('ignore',category=FutureWarning)\n","\n","import librosa, IPython, datetime, time, os, sys, copy, dill, pickle, mir_eval, glob\n","import numpy as np\n","import pandas as pd\n","from time import gmtime, strftime\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()\n","from matplotlib import pyplot as plt\n","from tf_ops import *\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","print (\"[info] Current Time:     \" + datetime.datetime.now().strftime('%Y/%m/%d  %H:%M:%S'))\n","print (\"[info] Python Version:   \" + sys.version.split('\\n')[0].split(' ')[0])\n","print (\"[info] Working Dir:      \" + os.getcwd()+'/')\n","\n","# enable gpu usage constraint here\n","fixed_gpu_usage = 1\n","selected_gpu_id = 0\n","\n","# if gpu usage is constraint, limit certain gpu for use\n","if (fixed_gpu_usage == 1):\n","    # set available GPU\n","    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"        # list GPU sequence by PCI bus GPU ID\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(selected_gpu_id)  \n","\n","    # check available GPU\n","    from tensorflow.python.client import device_lib\n","    for x in range(1, len(device_lib.list_local_devices())):\n","        print (\"[info] GPU \" + device_lib.list_local_devices()[x].physical_device_desc)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[info] Current Time:     2021/06/30  05:05:16\n","[info] Python Version:   3.7.10\n","[info] Working Dir:      /content/drive/MyDrive/Drum_SSM/drum_generation_with_ssm/\n","[info] GPU device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q2h3zGjBpK0t"},"source":["# Define SSM data batch reader"]},{"cell_type":"code","metadata":{"id":"sL3wPV9dpK0t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625029519242,"user_tz":-330,"elapsed":700,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"ea21148e-c23b-4002-fa67-96f0751ff9bd"},"source":["test_file_names_list = np.sort(glob.glob('./pre_processed_data/merged_ssm_pkg/*.pkl', recursive=True)).tolist()\n","print ('[info] Total test files: {}'.format(len(test_file_names_list)))\n","\n","total_test_files_num = len(test_file_names_list)   \n","\n","def get_batch_ssm_data(get_batch_num=total_test_files_num):\n","\n","    batch_file_names_list = copy.deepcopy([test_file_names_list[x] for x in list(range(0, total_test_files_num))])\n","    \n","    cqt_ssm_batch_list = []\n","    drum_ssm_batch_list = []\n","    song_bars_len_list = []    \n","    \n","    for file_name_read in batch_file_names_list:\n","        \n","        with open(file_name_read, 'rb') as pkl_file:        \n","            reload_data_package = pickle.load(pkl_file)\n","            \n","        cqt_ssm_data = reload_data_package[0].astype(np.float32)\n","        drum_ssm_data = reload_data_package[1].astype(np.float32)          \n","        song_bars_len = reload_data_package[4]\n","        \n","        # save data into list\n","        cqt_ssm_batch_list.append(cqt_ssm_data)\n","        drum_ssm_batch_list.append(drum_ssm_data)\n","        song_bars_len_list.append(song_bars_len)\n","    \n","    # merge batch data\n","    ssm_batch_output = [cqt_ssm_batch_list, \n","                        drum_ssm_batch_list, \n","                        song_bars_len_list]\n","    \n","    return(ssm_batch_output)\n","\n","print ('[info] Data loader define done.')\n","\n","\n","print('')\n","\n","picked_song_idx = 20\n","print ('[info] CQT SSM shape: {}'.format(get_batch_ssm_data()[0][picked_song_idx].shape))\n","print ('[info] Drum SSM shape: {}'.format(get_batch_ssm_data()[1][picked_song_idx].shape))\n","print ('[info] Song bars len shape: {}'.format(get_batch_ssm_data()[2][picked_song_idx]))\n","\n","# get CQT SSM shape\n","cqt_ssm_shape = get_batch_ssm_data()[0][0].shape"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[info] Total test files: 24\n","[info] Data loader define done.\n","\n","[info] CQT SSM shape: (256, 256, 3)\n","[info] Drum SSM shape: (256, 256, 3)\n","[info] Song bars len shape: 140\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lb9MxTxZpK0u","executionInfo":{"status":"ok","timestamp":1625029519242,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NU20UvugpK0u"},"source":["# Define tensorflow placeholder"]},{"cell_type":"code","metadata":{"id":"iRLqC0FNpK0v","executionInfo":{"status":"ok","timestamp":1625029519243,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":["cqt_ssm_ph = tf.placeholder(tf.float32, shape=[None, \n","                                               cqt_ssm_shape[0], \n","                                               cqt_ssm_shape[1], \n","                                               cqt_ssm_shape[2]])"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5L_x9961pK0v"},"source":["# Define drum SSM generator"]},{"cell_type":"code","metadata":{"id":"BYQGCNoTpK0v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625029519243,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"3b8ec8c7-59f8-4853-ea4e-8b7b706d0255"},"source":["# define drum_arranger\n","def ssm_arranger(sarr_cqt_ssm_input,                 # input data shape = (batch_num, 256, 256, 3)\n","                 reuse=False):\n","                \n","    with tf.variable_scope('sarr', reuse=reuse):\n","        \n","        if reuse:\n","            tf.get_variable_scope().reuse_variables()\n","        else:\n","            assert tf.get_variable_scope().reuse is False\n","        \n","        # set basic parameters\n","        fmap_layer = 48\n","        #keep_prob = 0.8\n","        unet_output_c_dim = 1\n","        \n","        e0 = sarr_cqt_ssm_input\n","            \n","        # image is (256 x 256 x input_c_dim)\n","        e1 = tf.nn.elu(instance_norm(conv2d(e0, fmap_layer*1, name='g_e1_conv'), 'g_bn_e1'))\n","        # e1 is (128 x 128 x self.gf_dim)\n","        e2 = tf.nn.elu(instance_norm(conv2d(e1, fmap_layer*2, name='g_e2_conv'), 'g_bn_e2'))\n","        # e2 is (64 x 64 x self.gf_dim*2)\n","        e3 = tf.nn.elu(instance_norm(conv2d(e2, fmap_layer*4, name='g_e3_conv'), 'g_bn_e3'))\n","        # e3 is (32 x 32 x self.gf_dim*4)\n","        e4 = tf.nn.elu(instance_norm(conv2d(e3, fmap_layer*4, name='g_e4_conv'), 'g_bn_e4'))\n","        # e4 is (16 x 16 x self.gf_dim*8)\n","        e5 = tf.nn.elu(instance_norm(conv2d(e4, fmap_layer*4, name='g_e5_conv'), 'g_bn_e5'))\n","        # e5 is (8 x 8 x self.gf_dim*8)\n","        e6 = tf.nn.elu(instance_norm(conv2d(e5, fmap_layer*4, name='g_e6_conv'), 'g_bn_e6'))\n","        # e6 is (4 x 4 x self.gf_dim*8)\n","        e7 = tf.nn.elu(instance_norm(conv2d(e6, fmap_layer*4, name='g_e7_conv'), 'g_bn_e7'))\n","        # e7 is (2 x 2 x self.gf_dim*8)\n","        e8 = tf.nn.elu(instance_norm(conv2d(e7, fmap_layer*4, name='g_e8_conv'), 'g_bn_e8'))\n","        # e8 is (1 x 1 x self.gf_dim*8)\n","\n","        d1 = tf.nn.elu(instance_norm(deconv2d(e8, fmap_layer*4, name='g_d1'), 'g_bn_d1'))\n","        #d1 = tf.nn.dropout(d1, keep_prob)\n","        d1 = tf.concat([d1, e7*0.2], axis=3)\n","        # d1 is (2 x 2 x self.gf_dim*8*2)\n","\n","        d2 = tf.nn.elu(instance_norm(deconv2d(d1, fmap_layer*4, name='g_d2'), 'g_bn_d2'))\n","        #d2 = tf.nn.dropout(d2, keep_prob)\n","        d2 = tf.concat([d2, e6*0.20], axis=3)\n","        # d2 is (4 x 4 x self.gf_dim*8*2)\n","\n","        d3 = tf.nn.elu(instance_norm(deconv2d(d2, fmap_layer*4, name='g_d3'), 'g_bn_d3'))\n","        #d3 = tf.nn.dropout(d3, keep_prob)\n","        d3 = tf.concat([d3, e5*0.20], axis=3)\n","        # d3 is (8 x 8 x self.gf_dim*8*2)\n","\n","        d4 = tf.nn.elu(instance_norm(deconv2d(d3, fmap_layer*4, name='g_d4'), 'g_bn_d4'))\n","        d4 = tf.concat([d4, e4*0.20], axis=3)\n","        # d4 is (16 x 16 x self.gf_dim*8*2)\n","\n","        d5 = tf.nn.elu(instance_norm(deconv2d(d4, fmap_layer*4, name='g_d5'), 'g_bn_d5'))\n","        d5 = tf.concat([d5, e3*0.10], axis=3)\n","        # d5 is (32 x 32 x self.gf_dim*4*2)\n","\n","        d6 = tf.nn.elu(instance_norm(deconv2d(d5, fmap_layer*2, name='g_d6'), 'g_bn_d6'))\n","        d6 = tf.concat([d6, e2*0.05], axis=3)\n","        # d6 is (64 x 64 x self.gf_dim*2*2)\n","\n","        d7 = tf.nn.elu(instance_norm(deconv2d(d6, fmap_layer*2, name='g_d7'), 'g_bn_d7'))\n","        d7 = tf.concat([d7, e1*0.025], axis=3)\n","        # d7 is (128 x 128 x self.gf_dim*1*2)\n","\n","        #d8 = deconv2d(tf.nn.elu(d7), unet_output_c_dim, name='g_d8')\n","        d8 = deconv2d(d7, unet_output_c_dim, name='g_d8')\n","        # d8 is (256 x 256 x output_c_dim)\n","        \n","        # finally get output\n","        #sarr_output = tf.nn.tanh(d8) * 200\n","        sarr_output = d8\n","        \n","        return (sarr_output)\n","    \n","print ('Model define done.')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model define done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6L4BvkvfpK0x"},"source":["# Connect model"]},{"cell_type":"code","metadata":{"id":"GhUrqvZbpK0x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625029520184,"user_tz":-330,"elapsed":946,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"9f89b45d-9b9c-4799-82ed-0fe9a5c91913"},"source":["# connect model data-flow\n","sarr_output_data = ssm_arranger(cqt_ssm_ph, reuse=False)\n","\n","print('[info] model data-flow wire are connected.')\n","\n","# Define all trainable variable\n","t_vars = tf.trainable_variables()\n","sarr_vars = [var for var in t_vars if 'sarr' in var.name]\n","\n","print('[info] model vars are defined.')\n","\n","# count model trainable variables\n","print('[info] Total params: {}'.format(np.sum([np.prod(v.shape) for v in t_vars])))\n","\n","print('[info] trainable variables: \\n')\n","print([var.name for var in sarr_vars])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/drive/MyDrive/Drum_SSM/drum_generation_with_ssm/tf_ops.py:16: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["[info] model data-flow wire are connected.\n","[info] model vars are defined.\n","[info] Total params: 9520416\n","[info] trainable variables: \n","\n","['sarr/g_e1_conv/Conv/weights:0', 'sarr/g_bn_e1/scale:0', 'sarr/g_bn_e1/offset:0', 'sarr/g_e2_conv/Conv/weights:0', 'sarr/g_bn_e2/scale:0', 'sarr/g_bn_e2/offset:0', 'sarr/g_e3_conv/Conv/weights:0', 'sarr/g_bn_e3/scale:0', 'sarr/g_bn_e3/offset:0', 'sarr/g_e4_conv/Conv/weights:0', 'sarr/g_bn_e4/scale:0', 'sarr/g_bn_e4/offset:0', 'sarr/g_e5_conv/Conv/weights:0', 'sarr/g_bn_e5/scale:0', 'sarr/g_bn_e5/offset:0', 'sarr/g_e6_conv/Conv/weights:0', 'sarr/g_bn_e6/scale:0', 'sarr/g_bn_e6/offset:0', 'sarr/g_e7_conv/Conv/weights:0', 'sarr/g_bn_e7/scale:0', 'sarr/g_bn_e7/offset:0', 'sarr/g_e8_conv/Conv/weights:0', 'sarr/g_bn_e8/scale:0', 'sarr/g_bn_e8/offset:0', 'sarr/g_d1/Conv2d_transpose/weights:0', 'sarr/g_bn_d1/scale:0', 'sarr/g_bn_d1/offset:0', 'sarr/g_d2/Conv2d_transpose/weights:0', 'sarr/g_bn_d2/scale:0', 'sarr/g_bn_d2/offset:0', 'sarr/g_d3/Conv2d_transpose/weights:0', 'sarr/g_bn_d3/scale:0', 'sarr/g_bn_d3/offset:0', 'sarr/g_d4/Conv2d_transpose/weights:0', 'sarr/g_bn_d4/scale:0', 'sarr/g_bn_d4/offset:0', 'sarr/g_d5/Conv2d_transpose/weights:0', 'sarr/g_bn_d5/scale:0', 'sarr/g_bn_d5/offset:0', 'sarr/g_d6/Conv2d_transpose/weights:0', 'sarr/g_bn_d6/scale:0', 'sarr/g_bn_d6/offset:0', 'sarr/g_d7/Conv2d_transpose/weights:0', 'sarr/g_bn_d7/scale:0', 'sarr/g_bn_d7/offset:0', 'sarr/g_d8/Conv2d_transpose/weights:0']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yDGAVrulpK0y"},"source":["# Test SSM Model Arrangement"]},{"cell_type":"code","metadata":{"id":"EaCHEgfLpK0y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625029574863,"user_tz":-330,"elapsed":35191,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"22b4441b-af38-401d-b729-82923c15153a"},"source":["chkpt_ver = 'v13'\n","\n","saver = tf.train.Saver(var_list=sarr_vars)\n","\n","sarr_config = tf.ConfigProto(allow_soft_placement=True)\n","sarr_config.gpu_options.allow_growth = True\n","\n","with tf.Session(config=sarr_config) as sess:\n","    \n","    saver.restore(sess, './ssm_generator_model/sarr_model.ckpt'.format(chkpt_ver, chkpt_ver))\n","    print ('[info] Model parameters are loaded.\\n')    \n","\n","    test_cqt_data_list = []\n","    test_drum_data_sample_gt_list = []\n","    test_drum_data_sample_list = []\n","    test_song_length_data_list = []\n","    \n","    run_loops_num = 1\n","    \n","    print ('[info] Start testing...')\n","    print (datetime.datetime.now().strftime('[info] %Y-%m-%d %H:%M:%S') + '\\n')\n","    \n","    for calculate_score_idx in range(0, run_loops_num):        \n","\n","        # get test data for test\n","        test_batch_ssm_data_tmp = get_batch_ssm_data()                \n","        # get train data for test                \n","        test_cqt_ssm_data = np.array(test_batch_ssm_data_tmp[0])     # (batch_num_test, 256, 256, 3)\n","        \n","        # get batch ground-truth data\n","        test_drum_ssm_data = np.array(test_batch_ssm_data_tmp[1])    # (batch_num_test, 256, 256, 3)\n","        \n","        # get song length data     \n","        test_song_len_data = np.array(test_batch_ssm_data_tmp[2])    # (batch_num, 1)             \n","        \n","        # get drum arrangement test result\n","        test_sarr_sample = sess.run(ssm_arranger(cqt_ssm_ph, reuse=True),\n","                                                   feed_dict={cqt_ssm_ph:     test_cqt_ssm_data, \n","                                                              #drum_ssm_ph:    test_drum_ssm_data,\n","                                                              #ssm_mask_ph:    test_ssm_mask_data,\n","                                                              #pix_mean_ph:    test_pix_mean_data\n","                                                              })\n","\n","        test_cqt_data_list.append(test_cqt_ssm_data)\n","        test_drum_data_sample_gt_list.append(test_drum_ssm_data)\n","        test_drum_data_sample_list.append(test_sarr_sample)\n","        test_song_length_data_list.append(test_song_len_data)    \n","        \n","                                                                                                                         \n","        # show progress\n","        #if (calculate_score_idx+1)%5==0:\n","        write_msg = '[info] Test loop: [ {} / {} ]\\n'.format(calculate_score_idx+1, run_loops_num)\n","        #    write_msg += 'Training Loss: {:.6f} ,  '.format(np.mean(tr_loss_value))\n","        #    write_msg += 'Testing Loss: {:.6f}'.format(np.mean(te_loss_value))\n","        print (write_msg)\n","            \n","\n","# total Avg. show score\n","print (\"[info] Drum SSM arrange test is finished.\")\n","print (\"[info] Songs tested: {}\".format(len(test_drum_data_sample_list[0])))\n","print (datetime.datetime.now().strftime('[info] %Y-%m-%d %H:%M:%S') + '\\n')\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./ssm_generator_model/sarr_model.ckpt\n","[info] Model parameters are loaded.\n","\n","[info] Start testing...\n","[info] 2021-06-30 05:05:41\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["[info] Test loop: [ 1 / 1 ]\n","\n","[info] Drum SSM arrange test is finished.\n","[info] Songs tested: 24\n","[info] 2021-06-30 05:06:13\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_HGoPk2QpK0y","executionInfo":{"status":"ok","timestamp":1625029574864,"user_tz":-330,"elapsed":26,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":[""],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rb0asA_YpK0z"},"source":["# Define function to extract rectangular ssm data"]},{"cell_type":"code","metadata":{"id":"93bKOt36pK0z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625029577430,"user_tz":-330,"elapsed":631,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"2e974caa-6cd0-4e19-d88f-9ec574b54f39"},"source":["# rotate SSM, crop to original size\n","def get_extracted_full_ssm(ges_ssm_input, ges_song_len_input):\n","    \n","    ges_output = ges_ssm_input[0:ges_song_len_input, 0:ges_song_len_input]\n","    ges_output_final = copy.deepcopy(ges_output)\n","    \n","    return (ges_output_final)\n","\n","# rotate SSM, crop to original size\n","def get_extracted_triangle_ssm(ges_ssm_input, ges_song_len_input):\n","    \n","    ges_output = ges_ssm_input[0:ges_song_len_input, 0:ges_song_len_input]\n","    ges_output_triu_1 = np.triu(ges_output, k=0)\n","    ges_output_triu_2 = np.rot90(np.flipud(np.triu(ges_output, k=1)), k=-1)\n","    ges_output_final = copy.deepcopy(ges_output_triu_1 + ges_output_triu_2)\n","    \n","    return (ges_output_final)\n","\n","import cv2, IPython, os\n","\n","def resize_ssm_762(rf7_input_figure):\n","    \n","    save_data = rf7_input_figure\n","    save_file_name = './saving_tmp_file.png'\n","\n","    fig = plt.figure(figsize=[8,8])\n","    ax = fig.add_subplot(111)\n","\n","    ax.imshow(save_data,\n","              origin='lower', \n","              cmap='hot')\n","\n","    ax.axes.get_xaxis().set_visible(False)\n","    ax.axes.get_yaxis().set_visible(False)\n","    ax.set_frame_on(False)\n","\n","    plt.savefig(save_file_name,\n","                dpi=50,\n","                bbox_inches='tight',\n","                pad_inches=0)\n","\n","    #plt.show()\n","    plt.close()\n","\n","    #IPython.display.clear_output()\n","\n","    img_readback = cv2.imread(save_file_name)\n","    \n","    os.remove(save_file_name)\n","    \n","    img_readback = np.mean(img_readback, axis=-1)\n","    \n","    return(-img_readback)\n","\n","print ('function define done.')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["function define done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n02Zd_h0pK00"},"source":["# Plot Testing Songs SSM"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"yhbn_pGLpK00","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Q9nFEw2PDEWY4jnjVMxJ_VKJzK5Vmg-2"},"executionInfo":{"status":"ok","timestamp":1625029595774,"user_tz":-330,"elapsed":12558,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"1b818fba-2d12-4885-f008-2a995733c0ba"},"source":["show_songs = total_test_files_num\n","#show_songs = 2\n","\n","batch_idx = 0\n","\n","batch_idx_list = list(range(total_test_files_num))\n","\n","#np.random.shuffle(batch_idx_list)\n","\n","song_idx_list = []\n","song_bars_num_list = []\n","\n","# loop over songs to collect SSM data\n","for k, song_idx in enumerate(batch_idx_list[:show_songs]):\n","\n","    # get song data\n","    cqt_trangle_ssm =    copy.copy(test_cqt_data_list[batch_idx][song_idx][:,:,0])\n","    drum_trangle_ssm =   copy.copy(test_drum_data_sample_gt_list[batch_idx][song_idx][:,:,0])\n","    drum_model_ssm =     copy.copy(test_drum_data_sample_list[batch_idx][song_idx][:,:,0])\n","    song_bars_num =      copy.copy(test_song_length_data_list[batch_idx][song_idx])\n","\n","    cqt_restored_ssm =         resize_ssm_762(get_extracted_full_ssm(cqt_trangle_ssm, song_bars_num))\n","    drum_restored_ssm =        resize_ssm_762(get_extracted_full_ssm(drum_trangle_ssm, song_bars_num))\n","    drum_model_restored_ssm =  resize_ssm_762(get_extracted_triangle_ssm(drum_model_ssm, song_bars_num))\n","\n","    cqt_drum_model_ssm = np.hstack([cqt_restored_ssm, \n","                                    drum_restored_ssm, \n","                                    drum_model_restored_ssm])\n","    \n","    if k==0:        \n","        cqt_drum_model_ssm_all = cqt_drum_model_ssm\n","        \n","    else:        \n","        cqt_drum_model_ssm_all = np.vstack([cqt_drum_model_ssm_all, \n","                                            cqt_drum_model_ssm])\n","\n","\n","    song_idx_list.append(song_idx)\n","    song_bars_num_list.append(song_bars_num)\n","\n","    \n","# show songs info\n","for k, song_idx in enumerate(test_song_length_data_list[0].tolist()[:show_songs]):\n","    print ('Song idx: {}, length: {}'.format(k, song_idx))\n","\n","print ('\\n              ----melodic SSM----                  ----original drm SSM----               ----generated drum SSM----')\n","# plot actual song SSM\n","plt.figure(figsize=(8*2, 8*show_songs))\n","plt.imshow(cqt_drum_model_ssm_all, cmap='hot')\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"5eJTQJmwpK01","executionInfo":{"status":"ok","timestamp":1625029624522,"user_tz":-330,"elapsed":355,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NogLVfxkpK01"},"source":["# Save generated SSM"]},{"cell_type":"code","metadata":{"id":"KxMwvOEipK01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625029626698,"user_tz":-330,"elapsed":380,"user":{"displayName":"Rishabh Atul Dahale","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj43AZdGQDIcj4_lL1dHTZmTx77W06Kb5MH-nvK=s64","userId":"17621794671274840370"}},"outputId":"f5739832-ff3b-4834-b69f-b5ed7da9b29a"},"source":["n_bars_list_for_save = []\n","cqt_ssm_list_for_save = []\n","drum_ssm_list_for_save = []\n","drum_model_ssm_list_for_save = []\n","\n","\n","batch_idx = 0\n","\n","for song_idx in range(0, total_test_files_num):\n","    \n","    song_bars_num =      copy.copy(test_song_length_data_list[batch_idx][song_idx])\n","    \n","    cqt_trangle_ssm =    copy.copy(test_cqt_data_list[batch_idx][song_idx][:,:,0])\n","    drum_trangle_ssm =   copy.copy(test_drum_data_sample_gt_list[batch_idx][song_idx][:,:,0])\n","    drum_model_ssm =     copy.copy(test_drum_data_sample_list[batch_idx][song_idx][:,:,0])    \n","    \n","    extracted_cqt_ssm =          get_extracted_triangle_ssm(cqt_trangle_ssm, song_bars_num)\n","    extracted_drum_ssm =         get_extracted_full_ssm(drum_trangle_ssm, song_bars_num)\n","    extracted_drum_model_ssm =   get_extracted_triangle_ssm(drum_model_ssm, song_bars_num)\n","    \n","    print ('Song: {}, Bars: {}, SSM shape: {}'.format(song_idx+1, song_bars_num, extracted_drum_model_ssm.shape))\n","    \n","    n_bars_list_for_save.append(song_bars_num)\n","    cqt_ssm_list_for_save.append(extracted_cqt_ssm)\n","    drum_ssm_list_for_save.append(extracted_drum_ssm)\n","    drum_model_ssm_list_for_save.append(extracted_drum_model_ssm)\n","    \n","print ('\\n[info] conversion done')\n","\n","merged_ssm_data = [n_bars_list_for_save,\n","                   cqt_ssm_list_for_save,                   \n","                   drum_ssm_list_for_save,\n","                   drum_model_ssm_list_for_save]\n","\n","save_ssm_pkl_file_name = './pre_processed_data/model_out_drum_ssm_pkg.pkl'\n","\n","with open(save_ssm_pkl_file_name, 'wb') as pkl_file:\n","    pickle.dump(merged_ssm_data, pkl_file)\n","    \n","print ('\\n[info] All SSMs are saved.')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Song: 1, Bars: 101, SSM shape: (101, 101)\n","Song: 2, Bars: 81, SSM shape: (81, 81)\n","Song: 3, Bars: 91, SSM shape: (91, 91)\n","Song: 4, Bars: 94, SSM shape: (94, 94)\n","Song: 5, Bars: 86, SSM shape: (86, 86)\n","Song: 6, Bars: 84, SSM shape: (84, 84)\n","Song: 7, Bars: 101, SSM shape: (101, 101)\n","Song: 8, Bars: 91, SSM shape: (91, 91)\n","Song: 9, Bars: 88, SSM shape: (88, 88)\n","Song: 10, Bars: 79, SSM shape: (79, 79)\n","Song: 11, Bars: 140, SSM shape: (140, 140)\n","Song: 12, Bars: 68, SSM shape: (68, 68)\n","Song: 13, Bars: 74, SSM shape: (74, 74)\n","Song: 14, Bars: 62, SSM shape: (62, 62)\n","Song: 15, Bars: 109, SSM shape: (109, 109)\n","Song: 16, Bars: 67, SSM shape: (67, 67)\n","Song: 17, Bars: 111, SSM shape: (111, 111)\n","Song: 18, Bars: 95, SSM shape: (95, 95)\n","Song: 19, Bars: 52, SSM shape: (52, 52)\n","Song: 20, Bars: 118, SSM shape: (118, 118)\n","Song: 21, Bars: 140, SSM shape: (140, 140)\n","Song: 22, Bars: 133, SSM shape: (133, 133)\n","Song: 23, Bars: 100, SSM shape: (100, 100)\n","Song: 24, Bars: 146, SSM shape: (146, 146)\n","\n","[info] conversion done\n","\n","[info] All SSMs are saved.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zI_7aKMtpK02"},"source":[""],"execution_count":null,"outputs":[]}]}